# Dataset parameters
batch_size = 128
num_training_updates = 4000

# Encoder Decoder parameters
num_hiddens = 64
num_residual_hiddens = 32 
num_residual_layers = 2
embedding_dim = 8 
num_embeddings = 32

#EMA parameters
commitment_cost = 0.25
decay = 0#0.99

#training
learning_rate = 1e-3

#Hopfield lambda parameter
lambd = 0.001   

